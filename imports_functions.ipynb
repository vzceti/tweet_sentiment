{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import twitter_samples\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import csv\n",
    "import tweepy\n",
    "import io\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import ImageColorGenerator\n",
    "from wordcloud import STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "  stemmer = PorterStemmer() \n",
    "  stopwords_english = stopwords.words('english')\n",
    "\n",
    "  # remove the stock market tickers\n",
    "  tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "\n",
    "  # remove the old styles retweet text 'RT'\n",
    "  tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "\n",
    "  # remove the hyperlinks\n",
    "  tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "\n",
    "  # remove the # symbol\n",
    "  tweet = re.sub(r'#', '', tweet)\n",
    "\n",
    "  # Tokenize the tweet\n",
    "  tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "  tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "  tweet_clean = []\n",
    "\n",
    "  # removing stopwords and punctuation\n",
    "  for word in tweet_tokens:\n",
    "    if (word not in stopwords_english and\n",
    "        word not in string.punctuation):\n",
    "      stem_word = stemmer.stem(word)    #stemming\n",
    "      tweet_clean.append(stem_word)\n",
    "\n",
    "  return tweet_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tweets(tweets, ys):\n",
    "  ys_list = np.squeeze(ys).tolist()\n",
    "  freqs ={}\n",
    "\n",
    "  for y, tweet in zip(ys_list, tweets):\n",
    "    for word in process_tweet(tweet):\n",
    "      pair = (word, y)\n",
    "      if pair in freqs:\n",
    "        freqs[pair] +=1\n",
    "      else:\n",
    "        freqs[pair] = 1\n",
    "  \n",
    "  return freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(freqs, word, label):\n",
    "  n = 0\n",
    "  pair = (word, label)\n",
    "  if pair in freqs:\n",
    "    n = freqs[pair]\n",
    "  return n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "  logliklihood = {}\n",
    "  logprior = 0\n",
    "\n",
    "  # calculate V, number of unique words in the vocabulary\n",
    "  vocab = set([pair[0] for pair in freqs.keys()])\n",
    "  V = len(vocab)\n",
    "\n",
    "  ## Calculate N_pos, N_neg, V_pos, V_neg\n",
    "  # N_pos : total number of positive words\n",
    "  # N_neg : total number of negative words\n",
    "  # V_pos : total number of unique positive words\n",
    "  # V_neg : total number of unique negative words\n",
    "\n",
    "  N_pos = N_neg = V_pos = V_neg = 0\n",
    "  for pair in freqs.keys():\n",
    "    if pair[1]>0:\n",
    "      V_pos +=1\n",
    "      N_pos += freqs[pair]\n",
    "    else:\n",
    "      V_neg +=1\n",
    "      N_neg += freqs[pair]\n",
    "\n",
    "  # Number of tweets\n",
    "  D = len(train_y)\n",
    "\n",
    "  # D_pos, number of positive tweets\n",
    "  D_pos = len(list(filter(lambda x: x>0, train_y)))\n",
    "\n",
    "  # D_pos, number of negative tweets\n",
    "  D_neg = len(list(filter(lambda x: x<=0, train_y)))\n",
    "\n",
    "  # calculate the logprior\n",
    "  logprior = np.log(D_pos) - np.log(D_neg)\n",
    "\n",
    "  for word in vocab:\n",
    "    freqs_pos = lookup(freqs, word, 1)\n",
    "    freqs_neg = lookup(freqs, word, 0)\n",
    "\n",
    "    # calculte the probability of each word being positive and negative\n",
    "    p_w_pos = (freqs_pos+1)/(N_pos+V)\n",
    "    p_w_neg = (freqs_neg+1)/(N_neg+V)\n",
    "\n",
    "    logliklihood[word] = np.log(p_w_pos/p_w_neg)\n",
    "  \n",
    "  return logprior, logliklihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
    "  word_l = process_tweet(tweet)\n",
    "  p = 0\n",
    "  p+=logprior\n",
    "\n",
    "  for word in word_l:\n",
    "    if word in loglikelihood:\n",
    "      p+=loglikelihood[word]\n",
    "\n",
    "  return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
    "  accuracy = 0\n",
    "  y_hats = []\n",
    "  for tweet in test_x:\n",
    "    if naive_bayes_predict(tweet, logprior, loglikelihood) > 0:\n",
    "      y_hat_i = 1\n",
    "    else:\n",
    "      y_hat_i = 0\n",
    "    y_hats.append(y_hat_i)\n",
    "  error = np.mean(np.absolute(test_y - y_hats))\n",
    "  accuracy = 1-error\n",
    "\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTweets(df_to_split):\n",
    "  df = []\n",
    "  for i in df_to_split:\n",
    "    #for j in i.split(\" \"):\n",
    "    for j in process_tweet(i):\n",
    "      if \"http\" in j or \"&\" in j or \"@\" in j or \"\\n\" in j:\n",
    "        continue\n",
    "      df.append(j.lower().strip())\n",
    "  df_new = pd.DataFrame(df)\n",
    "  return df_new.value_counts().rename_axis('unique_values').reset_index(name='counts')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee5e1442887e2b2e9acb09880c1665aeb7280f29d406a4248a74bfd7ca8aa1b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
